{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `formerly test_simulation_v6.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'bayanpy', 'wurlitzer', 'graph_tool'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'ASLPAw'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'wurlitzer'}\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import sonetsim\n",
    "import os\n",
    "\n",
    "num_logical_processors = mp.cpu_count()\n",
    "pd.set_option(\"display.max_columns\", 25)\n",
    "pd.set_option(\"display.width\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_num_logical_processors(n):\n",
    "    global num_logical_processors\n",
    "    num_logical_processors = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophilies = [x / 4 for x in range(1, 5)]\n",
    "isolations = [x / 4 for x in range(1, 5)]\n",
    "insulations = [x / 4 for x in range(1, 5)]\n",
    "affinities = [x / 4 for x in range(1, 5)]\n",
    "num_nodes = [50 * (x + 1) ** 2 for x in range(0, 5)]\n",
    "edge_multipliers = [2 * x for x in range(1, 6)]\n",
    "num_communities = [2 * x**2 for x in range(1, 6)]\n",
    "# resloutions      = [x/4 for x in range(0,5)]\n",
    "# resloutions      = [1]\n",
    "\n",
    "\n",
    "def create_simulation_and_evaluation_grid_search(seed):\n",
    "    grid_search = []\n",
    "    for hom in homophilies:\n",
    "        for iso in isolations:\n",
    "            for ins in insulations:\n",
    "                for aff in affinities:\n",
    "                    for nns in num_nodes:\n",
    "                        for em in edge_multipliers:\n",
    "                            nes = int(nns * em)\n",
    "                            for ncs in num_communities:\n",
    "                                grid_search.append(\n",
    "                                    [hom, iso, ins, aff, nns, nes, ncs, seed]\n",
    "                                )\n",
    "                                # for res in resloutions:\n",
    "                                #     grid_search.append([\n",
    "                                #         hom, iso, ins, aff,\n",
    "                                #         nns, nes, ncs, res,\n",
    "                                #         seed\n",
    "                                #     ])\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = [\n",
    "    \"algorithm\",\n",
    "    \"community\",\n",
    "    \"target_homophily\",\n",
    "    \"target_isolation\",\n",
    "    \"target_insulation\",\n",
    "    \"target_affinity\",\n",
    "    \"num_nodes\",\n",
    "    \"num_edges\",\n",
    "    \"edge_multiplier\",\n",
    "    \"num_communities\",\n",
    "    \"resolution\",\n",
    "    \"seed\",\n",
    "]\n",
    "num_batches = 111\n",
    "# eval_dir = \"/workspace/research/Funded/Ethical_Reccomendations/Paper_Poster/ACM/EchoChambers/FigTeX/EX-Networks/Method/JUPYT/Simulator/soscsim/checkpoints_v2/mega_eval_df/\"\n",
    "eval_dir = \"/mnt/r/Funded/Ethical_Reccomendations/Paper_Poster/ACM/EchoChambers/FigTeX/EX-Networks/Method/JUPYT/Simulator/soscsim/checkpoints_v2/mega_eval_df/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in range(0, 5, 1):\n",
    "    print(f\"working on seed {seed}\")\n",
    "    grid_search = create_simulation_and_evaluation_grid_search(seed)\n",
    "    _grid_search = create_simulation_and_evaluation_grid_search(seed)\n",
    "    chunk_size = len(grid_search) / num_batches\n",
    "\n",
    "    for n in range(num_batches):\n",
    "        if os.path.isfile(eval_dir + f\"seed_{seed}_batch_{n}.parquet\"):\n",
    "            print(f\"skipping seed {seed} batch {n}, already processed\")\n",
    "            print(\"------------------------------------\\n\")\n",
    "            continue\n",
    "        print(f\"working on seed {seed} batch {n}\")\n",
    "        batch = grid_search[int(chunk_size * n) : int(chunk_size * (n + 1))].copy()\n",
    "\n",
    "        print(f\"working on seed {seed} batch {n} graph simulations\")\n",
    "        with mp.Pool(num_logical_processors) as pool:\n",
    "            graphs = pool.starmap(func=sonetsim.simulation, iterable=batch)\n",
    "\n",
    "        _batch = _grid_search[int(chunk_size * n) : int(chunk_size * (n + 1))]\n",
    "        params = []\n",
    "        for param_set, graph in zip(_batch, graphs):\n",
    "            params.append(param_set + list(graph))\n",
    "\n",
    "        print(f\"working on seed {seed} batch {n} parallel algorithms\")\n",
    "        with mp.Pool(num_logical_processors) as pool:\n",
    "            evals = pool.starmap(\n",
    "                func=sonetsim.evaluate_communities_parallel, iterable=params\n",
    "            )\n",
    "\n",
    "        print(f\"working on seed {seed} batch {n} serial algorithms\")\n",
    "        for param_set in params:\n",
    "            evals.append(sonetsim.evaluate_communities_serial(*param_set))\n",
    "\n",
    "        print(f\"working on seed {seed} batch {n} saving\")\n",
    "        mega_eval_df = pd.concat(evals)\n",
    "        mega_eval_df.to_parquet(eval_dir + f\"seed_{seed}_batch_{n}.parquet\")\n",
    "        print(\"------------------------------------\\n\")\n",
    "    print(\"----------------------------------------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
